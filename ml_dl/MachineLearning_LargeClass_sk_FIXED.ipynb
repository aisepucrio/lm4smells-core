{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498e3cf1",
   "metadata": {},
   "source": [
    "# MachineLearning_LargeClass_sk — **VERSÃO CORRIGIDA (sem data leakage)**\n",
    "\n",
    "Este notebook corrige o problema de *data leakage* causado por balanceamento antes do split.\n",
    "Agora o balanceamento é aplicado **apenas no conjunto de treino** e, no caso do PyCaret, **dentro dos folds** via SMOTE.\n",
    "\n",
    "> **Binário**: código preparado para classificação binária (`smell_label` ∈ {0,1} ou equivalentes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d465d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "try:\n",
    "    from pycaret.classification import setup, compare_models, pull, finalize_model, predict_model, get_config, save_model\n",
    "    _HAS_PYCARET = True\n",
    "except Exception as e:\n",
    "    print('PyCaret não disponível neste ambiente. Você ainda pode usar a Opção B (Sklearn/Imblearn).')\n",
    "    _HAS_PYCARET = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b6524",
   "metadata": {},
   "source": [
    "## 1) Carregar dados\n",
    "\n",
    "> Ajuste o caminho do CSV se necessário.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30352993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8169, 14) ['raw_sloc', 'raw_multi', 'raw_blank', 'raw_single_comments', 'hal_func_N2', 'hal_func_vocabulary', 'hal_func_length', 'hal_func_calculated_length', 'hal_func_volume', 'hal_func_difficulty', 'hal_func_effort', 'hal_func_time', 'hal_func_bugs', 'smell_label']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_sloc</th>\n",
       "      <th>raw_multi</th>\n",
       "      <th>raw_blank</th>\n",
       "      <th>raw_single_comments</th>\n",
       "      <th>hal_func_N2</th>\n",
       "      <th>hal_func_vocabulary</th>\n",
       "      <th>hal_func_length</th>\n",
       "      <th>hal_func_calculated_length</th>\n",
       "      <th>hal_func_volume</th>\n",
       "      <th>hal_func_difficulty</th>\n",
       "      <th>hal_func_effort</th>\n",
       "      <th>hal_func_time</th>\n",
       "      <th>hal_func_bugs</th>\n",
       "      <th>smell_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>488.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>294.284957</td>\n",
       "      <td>484.129871</td>\n",
       "      <td>5.744681</td>\n",
       "      <td>2781.171600</td>\n",
       "      <td>154.509533</td>\n",
       "      <td>0.161377</td>\n",
       "      <td>large-class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>381.426462</td>\n",
       "      <td>760.932855</td>\n",
       "      <td>4.762295</td>\n",
       "      <td>3623.786794</td>\n",
       "      <td>201.321489</td>\n",
       "      <td>0.253644</td>\n",
       "      <td>large-class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>581.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>1915.006330</td>\n",
       "      <td>4730.236212</td>\n",
       "      <td>3.294606</td>\n",
       "      <td>15584.263701</td>\n",
       "      <td>865.792428</td>\n",
       "      <td>1.576745</td>\n",
       "      <td>large-class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454.0</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1310.581943</td>\n",
       "      <td>3071.659769</td>\n",
       "      <td>4.706897</td>\n",
       "      <td>14457.984777</td>\n",
       "      <td>803.221377</td>\n",
       "      <td>1.023887</td>\n",
       "      <td>large-class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>693.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>2400.966744</td>\n",
       "      <td>4800.293813</td>\n",
       "      <td>13.345070</td>\n",
       "      <td>64060.258981</td>\n",
       "      <td>3558.903277</td>\n",
       "      <td>1.600098</td>\n",
       "      <td>large-class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_sloc  raw_multi  raw_blank  raw_single_comments  hal_func_N2  \\\n",
       "0     488.0      284.0      104.0                  0.0         54.0   \n",
       "1     179.0      421.0      138.0                  0.0         83.0   \n",
       "2     581.0     1939.0      685.0                  0.0        397.0   \n",
       "3     454.0     1672.0      494.0                  0.0        273.0   \n",
       "4     693.0      661.0      192.0                  0.0        379.0   \n",
       "\n",
       "   hal_func_vocabulary  hal_func_length  hal_func_calculated_length  \\\n",
       "0                 57.0             83.0                  294.284957   \n",
       "1                 68.0            125.0                  381.426462   \n",
       "2                245.0            596.0                 1915.006330   \n",
       "3                180.0            410.0                 1310.581943   \n",
       "4                304.0            582.0                 2400.966744   \n",
       "\n",
       "   hal_func_volume  hal_func_difficulty  hal_func_effort  hal_func_time  \\\n",
       "0       484.129871             5.744681      2781.171600     154.509533   \n",
       "1       760.932855             4.762295      3623.786794     201.321489   \n",
       "2      4730.236212             3.294606     15584.263701     865.792428   \n",
       "3      3071.659769             4.706897     14457.984777     803.221377   \n",
       "4      4800.293813            13.345070     64060.258981    3558.903277   \n",
       "\n",
       "   hal_func_bugs  smell_label  \n",
       "0       0.161377  large-class  \n",
       "1       0.253644  large-class  \n",
       "2       1.576745  large-class  \n",
       "3       1.023887  large-class  \n",
       "4       1.600098  large-class  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Load data\n",
    "# =========================\n",
    "CSV_PATH = 'dataset_large_class.csv'  \n",
    "TARGET = 'smell_label'\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(df.shape, df.columns.tolist())\n",
    "df[TARGET] = df[TARGET].astype('category')  # assegura tipo categórico\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd68b5",
   "metadata": {},
   "source": [
    "## 2) Split estratificado (sem balancear aqui)\n",
    "\n",
    "Criamos **train/test** primeiro para evitar vazamento. Qualquer balanceamento ocorrerá **apenas no treino**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695ec53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição antes (dataset completo):\n",
      "smell_label\n",
      "non-large-class    8130\n",
      "large-class          39\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Treino: (6535,)  Teste: (1634,)\n",
      "\n",
      "Distribuição no treino:\n",
      "smell_label\n",
      "non-large-class    6504\n",
      "large-class          31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuição no teste:\n",
      "smell_label\n",
      "non-large-class    1626\n",
      "large-class           8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 2) Train/Test Split\n",
    "# =========================\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print('Distribuição antes (dataset completo):')\n",
    "print(y.value_counts())\n",
    "print('\\nTreino:', y_train.shape, ' Teste:', y_test.shape)\n",
    "print('\\nDistribuição no treino:')\n",
    "print(y_train.value_counts())\n",
    "print('\\nDistribuição no teste:')\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e22fb4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3A) **Opção A** — PyCaret com SMOTE **dentro do CV** (recomendado se você já usa PyCaret)\n",
    "\n",
    "- O `setup` usa **apenas o treino**.\n",
    "- `fix_imbalance=True` e `SMOTE` aplicado **dentro de cada fold**, evitando vazamento.\n",
    "- Modelo final é avaliado no **conjunto de teste externo**.\n",
    "\n",
    "> Se PyCaret não estiver instalado, pule para a **Opção B**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9764a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6e866 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6e866_row0_col0, #T_6e866_row0_col2, #T_6e866_row1_col0, #T_6e866_row1_col2, #T_6e866_row1_col4, #T_6e866_row1_col5, #T_6e866_row1_col6, #T_6e866_row1_col7, #T_6e866_row2_col0, #T_6e866_row2_col1, #T_6e866_row2_col2, #T_6e866_row2_col3, #T_6e866_row2_col4, #T_6e866_row2_col5, #T_6e866_row2_col6, #T_6e866_row2_col7, #T_6e866_row3_col0, #T_6e866_row3_col1, #T_6e866_row3_col2, #T_6e866_row3_col3, #T_6e866_row3_col4, #T_6e866_row3_col5, #T_6e866_row3_col6, #T_6e866_row3_col7, #T_6e866_row4_col0, #T_6e866_row4_col1, #T_6e866_row4_col2, #T_6e866_row4_col3, #T_6e866_row4_col4, #T_6e866_row4_col5, #T_6e866_row4_col6, #T_6e866_row4_col7, #T_6e866_row5_col0, #T_6e866_row5_col1, #T_6e866_row5_col2, #T_6e866_row5_col3, #T_6e866_row5_col4, #T_6e866_row5_col5, #T_6e866_row5_col6, #T_6e866_row5_col7, #T_6e866_row6_col0, #T_6e866_row6_col1, #T_6e866_row6_col2, #T_6e866_row6_col3, #T_6e866_row6_col4, #T_6e866_row6_col5, #T_6e866_row6_col6, #T_6e866_row6_col7, #T_6e866_row7_col0, #T_6e866_row7_col1, #T_6e866_row7_col3, #T_6e866_row7_col4, #T_6e866_row7_col5, #T_6e866_row7_col6, #T_6e866_row7_col7, #T_6e866_row8_col0, #T_6e866_row8_col1, #T_6e866_row8_col2, #T_6e866_row8_col3, #T_6e866_row8_col4, #T_6e866_row8_col5, #T_6e866_row8_col6, #T_6e866_row8_col7, #T_6e866_row9_col0, #T_6e866_row9_col1, #T_6e866_row9_col2, #T_6e866_row9_col3, #T_6e866_row9_col4, #T_6e866_row9_col5, #T_6e866_row9_col6, #T_6e866_row9_col7, #T_6e866_row10_col0, #T_6e866_row10_col1, #T_6e866_row10_col2, #T_6e866_row10_col3, #T_6e866_row10_col4, #T_6e866_row10_col5, #T_6e866_row10_col6, #T_6e866_row10_col7, #T_6e866_row11_col0, #T_6e866_row11_col1, #T_6e866_row11_col2, #T_6e866_row11_col3, #T_6e866_row11_col4, #T_6e866_row11_col5, #T_6e866_row11_col6, #T_6e866_row11_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6e866_row0_col1, #T_6e866_row0_col3, #T_6e866_row0_col4, #T_6e866_row0_col5, #T_6e866_row0_col6, #T_6e866_row0_col7, #T_6e866_row1_col1, #T_6e866_row1_col3, #T_6e866_row7_col2 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_6e866_row0_col8, #T_6e866_row1_col8, #T_6e866_row2_col8, #T_6e866_row3_col8, #T_6e866_row4_col8, #T_6e866_row5_col8, #T_6e866_row6_col8, #T_6e866_row7_col8, #T_6e866_row8_col8, #T_6e866_row9_col8, #T_6e866_row10_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_6e866_row11_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6e866\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e866_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6e866_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_6e866_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_6e866_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_6e866_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_6e866_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_6e866_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_6e866_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_6e866_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row0\" class=\"row_heading level0 row0\" >mlp</th>\n",
       "      <td id=\"T_6e866_row0_col0\" class=\"data row0 col0\" >MLP Classifier</td>\n",
       "      <td id=\"T_6e866_row0_col1\" class=\"data row0 col1\" >0.9926</td>\n",
       "      <td id=\"T_6e866_row0_col2\" class=\"data row0 col2\" >0.9452</td>\n",
       "      <td id=\"T_6e866_row0_col3\" class=\"data row0 col3\" >0.9926</td>\n",
       "      <td id=\"T_6e866_row0_col4\" class=\"data row0 col4\" >0.9967</td>\n",
       "      <td id=\"T_6e866_row0_col5\" class=\"data row0 col5\" >0.9941</td>\n",
       "      <td id=\"T_6e866_row0_col6\" class=\"data row0 col6\" >0.5396</td>\n",
       "      <td id=\"T_6e866_row0_col7\" class=\"data row0 col7\" >0.5843</td>\n",
       "      <td id=\"T_6e866_row0_col8\" class=\"data row0 col8\" >0.3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_6e866_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_6e866_row1_col1\" class=\"data row1 col1\" >0.9926</td>\n",
       "      <td id=\"T_6e866_row1_col2\" class=\"data row1 col2\" >0.8007</td>\n",
       "      <td id=\"T_6e866_row1_col3\" class=\"data row1 col3\" >0.9926</td>\n",
       "      <td id=\"T_6e866_row1_col4\" class=\"data row1 col4\" >0.9957</td>\n",
       "      <td id=\"T_6e866_row1_col5\" class=\"data row1 col5\" >0.9939</td>\n",
       "      <td id=\"T_6e866_row1_col6\" class=\"data row1 col6\" >0.4825</td>\n",
       "      <td id=\"T_6e866_row1_col7\" class=\"data row1 col7\" >0.5114</td>\n",
       "      <td id=\"T_6e866_row1_col8\" class=\"data row1 col8\" >0.2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row2\" class=\"row_heading level0 row2\" >knn</th>\n",
       "      <td id=\"T_6e866_row2_col0\" class=\"data row2 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_6e866_row2_col1\" class=\"data row2 col1\" >0.9864</td>\n",
       "      <td id=\"T_6e866_row2_col2\" class=\"data row2 col2\" >0.8698</td>\n",
       "      <td id=\"T_6e866_row2_col3\" class=\"data row2 col3\" >0.9864</td>\n",
       "      <td id=\"T_6e866_row2_col4\" class=\"data row2 col4\" >0.9953</td>\n",
       "      <td id=\"T_6e866_row2_col5\" class=\"data row2 col5\" >0.9902</td>\n",
       "      <td id=\"T_6e866_row2_col6\" class=\"data row2 col6\" >0.3468</td>\n",
       "      <td id=\"T_6e866_row2_col7\" class=\"data row2 col7\" >0.4102</td>\n",
       "      <td id=\"T_6e866_row2_col8\" class=\"data row2 col8\" >0.1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row3\" class=\"row_heading level0 row3\" >ridge</th>\n",
       "      <td id=\"T_6e866_row3_col0\" class=\"data row3 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_6e866_row3_col1\" class=\"data row3 col1\" >0.9832</td>\n",
       "      <td id=\"T_6e866_row3_col2\" class=\"data row3 col2\" >0.8182</td>\n",
       "      <td id=\"T_6e866_row3_col3\" class=\"data row3 col3\" >0.9832</td>\n",
       "      <td id=\"T_6e866_row3_col4\" class=\"data row3 col4\" >0.9948</td>\n",
       "      <td id=\"T_6e866_row3_col5\" class=\"data row3 col5\" >0.9882</td>\n",
       "      <td id=\"T_6e866_row3_col6\" class=\"data row3 col6\" >0.2907</td>\n",
       "      <td id=\"T_6e866_row3_col7\" class=\"data row3 col7\" >0.3570</td>\n",
       "      <td id=\"T_6e866_row3_col8\" class=\"data row3 col8\" >0.1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row4\" class=\"row_heading level0 row4\" >lda</th>\n",
       "      <td id=\"T_6e866_row4_col0\" class=\"data row4 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_6e866_row4_col1\" class=\"data row4 col1\" >0.9829</td>\n",
       "      <td id=\"T_6e866_row4_col2\" class=\"data row4 col2\" >0.8186</td>\n",
       "      <td id=\"T_6e866_row4_col3\" class=\"data row4 col3\" >0.9829</td>\n",
       "      <td id=\"T_6e866_row4_col4\" class=\"data row4 col4\" >0.9948</td>\n",
       "      <td id=\"T_6e866_row4_col5\" class=\"data row4 col5\" >0.9881</td>\n",
       "      <td id=\"T_6e866_row4_col6\" class=\"data row4 col6\" >0.2894</td>\n",
       "      <td id=\"T_6e866_row4_col7\" class=\"data row4 col7\" >0.3559</td>\n",
       "      <td id=\"T_6e866_row4_col8\" class=\"data row4 col8\" >0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row5\" class=\"row_heading level0 row5\" >nb</th>\n",
       "      <td id=\"T_6e866_row5_col0\" class=\"data row5 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_6e866_row5_col1\" class=\"data row5 col1\" >0.9816</td>\n",
       "      <td id=\"T_6e866_row5_col2\" class=\"data row5 col2\" >0.9207</td>\n",
       "      <td id=\"T_6e866_row5_col3\" class=\"data row5 col3\" >0.9816</td>\n",
       "      <td id=\"T_6e866_row5_col4\" class=\"data row5 col4\" >0.9955</td>\n",
       "      <td id=\"T_6e866_row5_col5\" class=\"data row5 col5\" >0.9875</td>\n",
       "      <td id=\"T_6e866_row5_col6\" class=\"data row5 col6\" >0.3067</td>\n",
       "      <td id=\"T_6e866_row5_col7\" class=\"data row5 col7\" >0.3978</td>\n",
       "      <td id=\"T_6e866_row5_col8\" class=\"data row5 col8\" >0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row6\" class=\"row_heading level0 row6\" >qda</th>\n",
       "      <td id=\"T_6e866_row6_col0\" class=\"data row6 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_6e866_row6_col1\" class=\"data row6 col1\" >0.9746</td>\n",
       "      <td id=\"T_6e866_row6_col2\" class=\"data row6 col2\" >0.9204</td>\n",
       "      <td id=\"T_6e866_row6_col3\" class=\"data row6 col3\" >0.9746</td>\n",
       "      <td id=\"T_6e866_row6_col4\" class=\"data row6 col4\" >0.9953</td>\n",
       "      <td id=\"T_6e866_row6_col5\" class=\"data row6 col5\" >0.9836</td>\n",
       "      <td id=\"T_6e866_row6_col6\" class=\"data row6 col6\" >0.2483</td>\n",
       "      <td id=\"T_6e866_row6_col7\" class=\"data row6 col7\" >0.3493</td>\n",
       "      <td id=\"T_6e866_row6_col8\" class=\"data row6 col8\" >0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row7\" class=\"row_heading level0 row7\" >lightgbm</th>\n",
       "      <td id=\"T_6e866_row7_col0\" class=\"data row7 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_6e866_row7_col1\" class=\"data row7 col1\" >0.9637</td>\n",
       "      <td id=\"T_6e866_row7_col2\" class=\"data row7 col2\" >0.9835</td>\n",
       "      <td id=\"T_6e866_row7_col3\" class=\"data row7 col3\" >0.9637</td>\n",
       "      <td id=\"T_6e866_row7_col4\" class=\"data row7 col4\" >0.9950</td>\n",
       "      <td id=\"T_6e866_row7_col5\" class=\"data row7 col5\" >0.9777</td>\n",
       "      <td id=\"T_6e866_row7_col6\" class=\"data row7 col6\" >0.2093</td>\n",
       "      <td id=\"T_6e866_row7_col7\" class=\"data row7 col7\" >0.3011</td>\n",
       "      <td id=\"T_6e866_row7_col8\" class=\"data row7 col8\" >0.0670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row8\" class=\"row_heading level0 row8\" >gpc</th>\n",
       "      <td id=\"T_6e866_row8_col0\" class=\"data row8 col0\" >Gaussian Process Classifier</td>\n",
       "      <td id=\"T_6e866_row8_col1\" class=\"data row8 col1\" >0.9285</td>\n",
       "      <td id=\"T_6e866_row8_col2\" class=\"data row8 col2\" >0.8713</td>\n",
       "      <td id=\"T_6e866_row8_col3\" class=\"data row8 col3\" >0.9285</td>\n",
       "      <td id=\"T_6e866_row8_col4\" class=\"data row8 col4\" >0.9948</td>\n",
       "      <td id=\"T_6e866_row8_col5\" class=\"data row8 col5\" >0.9585</td>\n",
       "      <td id=\"T_6e866_row8_col6\" class=\"data row8 col6\" >0.0963</td>\n",
       "      <td id=\"T_6e866_row8_col7\" class=\"data row8 col7\" >0.2048</td>\n",
       "      <td id=\"T_6e866_row8_col8\" class=\"data row8 col8\" >32.3350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row9\" class=\"row_heading level0 row9\" >rbfsvm</th>\n",
       "      <td id=\"T_6e866_row9_col0\" class=\"data row9 col0\" >SVM - Radial Kernel</td>\n",
       "      <td id=\"T_6e866_row9_col1\" class=\"data row9 col1\" >0.8185</td>\n",
       "      <td id=\"T_6e866_row9_col2\" class=\"data row9 col2\" >0.9260</td>\n",
       "      <td id=\"T_6e866_row9_col3\" class=\"data row9 col3\" >0.8185</td>\n",
       "      <td id=\"T_6e866_row9_col4\" class=\"data row9 col4\" >0.9945</td>\n",
       "      <td id=\"T_6e866_row9_col5\" class=\"data row9 col5\" >0.8955</td>\n",
       "      <td id=\"T_6e866_row9_col6\" class=\"data row9 col6\" >0.0344</td>\n",
       "      <td id=\"T_6e866_row9_col7\" class=\"data row9 col7\" >0.1194</td>\n",
       "      <td id=\"T_6e866_row9_col8\" class=\"data row9 col8\" >1.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row10\" class=\"row_heading level0 row10\" >svm</th>\n",
       "      <td id=\"T_6e866_row10_col0\" class=\"data row10 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_6e866_row10_col1\" class=\"data row10 col1\" >0.7777</td>\n",
       "      <td id=\"T_6e866_row10_col2\" class=\"data row10 col2\" >0.8957</td>\n",
       "      <td id=\"T_6e866_row10_col3\" class=\"data row10 col3\" >0.7777</td>\n",
       "      <td id=\"T_6e866_row10_col4\" class=\"data row10 col4\" >0.9942</td>\n",
       "      <td id=\"T_6e866_row10_col5\" class=\"data row10 col5\" >0.8677</td>\n",
       "      <td id=\"T_6e866_row10_col6\" class=\"data row10 col6\" >0.0257</td>\n",
       "      <td id=\"T_6e866_row10_col7\" class=\"data row10 col7\" >0.0982</td>\n",
       "      <td id=\"T_6e866_row10_col8\" class=\"data row10 col8\" >0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e866_level0_row11\" class=\"row_heading level0 row11\" >dummy</th>\n",
       "      <td id=\"T_6e866_row11_col0\" class=\"data row11 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_6e866_row11_col1\" class=\"data row11 col1\" >0.0048</td>\n",
       "      <td id=\"T_6e866_row11_col2\" class=\"data row11 col2\" >0.5000</td>\n",
       "      <td id=\"T_6e866_row11_col3\" class=\"data row11 col3\" >0.0048</td>\n",
       "      <td id=\"T_6e866_row11_col4\" class=\"data row11 col4\" >0.0000</td>\n",
       "      <td id=\"T_6e866_row11_col5\" class=\"data row11 col5\" >0.0000</td>\n",
       "      <td id=\"T_6e866_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n",
       "      <td id=\"T_6e866_row11_col7\" class=\"data row11 col7\" >0.0000</td>\n",
       "      <td id=\"T_6e866_row11_col8\" class=\"data row11 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24e27833ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top modelos (CV interno no treino):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.5843</td>\n",
       "      <td>0.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.8007</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.4825</td>\n",
       "      <td>0.5114</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.8186</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.2894</td>\n",
       "      <td>0.3559</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
       "mlp                  MLP Classifier    0.9926  0.9452  0.9926  0.9967  0.9941   \n",
       "lr              Logistic Regression    0.9926  0.8007  0.9926  0.9957  0.9939   \n",
       "knn          K Neighbors Classifier    0.9864  0.8698  0.9864  0.9953  0.9902   \n",
       "ridge              Ridge Classifier    0.9832  0.8182  0.9832  0.9948  0.9882   \n",
       "lda    Linear Discriminant Analysis    0.9829  0.8186  0.9829  0.9948  0.9881   \n",
       "\n",
       "        Kappa     MCC  TT (Sec)  \n",
       "mlp    0.5396  0.5843     0.317  \n",
       "lr     0.4825  0.5114     0.285  \n",
       "knn    0.3468  0.4102     0.179  \n",
       "ridge  0.2907  0.3570     0.171  \n",
       "lda    0.2894  0.3559     0.244  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2e171\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2e171_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_2e171_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_2e171_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_2e171_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_2e171_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_2e171_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_2e171_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_2e171_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2e171_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2e171_row0_col0\" class=\"data row0 col0\" >MLP Classifier</td>\n",
       "      <td id=\"T_2e171_row0_col1\" class=\"data row0 col1\" >0.9474</td>\n",
       "      <td id=\"T_2e171_row0_col2\" class=\"data row0 col2\" >0.8148</td>\n",
       "      <td id=\"T_2e171_row0_col3\" class=\"data row0 col3\" >0.9474</td>\n",
       "      <td id=\"T_2e171_row0_col4\" class=\"data row0 col4\" >0.9941</td>\n",
       "      <td id=\"T_2e171_row0_col5\" class=\"data row0 col5\" >0.9687</td>\n",
       "      <td id=\"T_2e171_row0_col6\" class=\"data row0 col6\" >0.1145</td>\n",
       "      <td id=\"T_2e171_row0_col7\" class=\"data row0 col7\" >0.2137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24e278c4e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (teste): 0.3940\n",
      "PR-AUC  (teste): 0.9932\n",
      "\n",
      "Classification report (teste):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    large-class     0.0667    0.7500    0.1224         8\n",
      "non-large-class     0.9987    0.9483    0.9729      1626\n",
      "\n",
      "       accuracy                         0.9474      1634\n",
      "      macro avg     0.5327    0.8492    0.5477      1634\n",
      "   weighted avg     0.9941    0.9474    0.9687      1634\n",
      "\n",
      "Confusion matrix (teste):\n",
      "[[   6    2]\n",
      " [  84 1542]]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3A) PyCaret (se disponível)\n",
    "# =========================\n",
    "if _HAS_PYCARET:\n",
    "    from imblearn.over_sampling import SMOTE  # para passar instância ao PyCaret\n",
    "\n",
    "    train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    s = setup(\n",
    "        data=train_df,\n",
    "        target=TARGET,\n",
    "        session_id=42,\n",
    "        fold=10,\n",
    "        fix_imbalance=True,\n",
    "        fix_imbalance_method=SMOTE(k_neighbors=5, random_state=42),\n",
    "        normalize=False,  \n",
    "        use_gpu=False, verbose=False\n",
    "    )\n",
    "\n",
    "    best = compare_models(sort='F1', turbo=False)\n",
    "    results = pull()\n",
    "    print('Top modelos (CV interno no treino):')\n",
    "    display(results.head())\n",
    "\n",
    "    final_model = finalize_model(best)\n",
    "\n",
    "    # Avaliação em teste externo\n",
    "    test_df = pd.concat([X_test.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1)\n",
    "    preds = predict_model(final_model, data=test_df)\n",
    "\n",
    "    # PyCaret retorna coluna 'Label' com predições\n",
    "    y_true = test_df[TARGET].astype(str).values\n",
    "    y_pred = preds['prediction_label'].astype(str).values\n",
    "\n",
    "    # Se houver Score/probabilidade para binário, calcula AUCs\n",
    "    prob_col = 'prediction_score'\n",
    "    if prob_col in preds.columns and preds[prob_col].notna().all():\n",
    "        try:\n",
    "            # Converter rótulos para {0,1} quando possível\n",
    "            classes = sorted(list(pd.Series(y_true).unique()))\n",
    "            if len(classes) == 2:\n",
    "                # map to 0/1\n",
    "                mapping = {cls:i for i, cls in enumerate(classes)}\n",
    "                y_true_bin = pd.Series(y_true).map(mapping).values\n",
    "                # Score do PyCaret costuma ser prob da classe positiva (verifique mapeamento dos labels)\n",
    "                roc_auc = roc_auc_score(y_true_bin, preds[prob_col].values)\n",
    "                pr_auc  = average_precision_score(y_true_bin, preds[prob_col].values)\n",
    "                print(f'ROC-AUC (teste): {roc_auc:.4f}')\n",
    "                print(f'PR-AUC  (teste): {pr_auc:.4f}')\n",
    "        except Exception as e:\n",
    "            print('Não foi possível calcular AUCs:', e)\n",
    "\n",
    "    print('\\nClassification report (teste):')\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    print('Confusion matrix (teste):')\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "else:\n",
    "    print('PyCaret não disponível — siga para a Opção B.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38beac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('label_encoding',\n",
       "                  TransformerWrapperWithInverse(exclude=None, include=None,\n",
       "                                                transformer=LabelEncoder())),\n",
       "                 ('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['raw_sloc', 'raw_multi',\n",
       "                                              'raw_blank', 'raw_single_comments',\n",
       "                                              'hal_func_N2',\n",
       "                                              'hal_func_vocabulary',\n",
       "                                              'hal_func_length',\n",
       "                                              'hal_func_calculated_length',...\n",
       "                                batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                early_stopping=False, epsilon=1e-08,\n",
       "                                hidden_layer_sizes=(100,),\n",
       "                                learning_rate='constant',\n",
       "                                learning_rate_init=0.001, max_fun=15000,\n",
       "                                max_iter=500, momentum=0.9, n_iter_no_change=10,\n",
       "                                nesterovs_momentum=True, power_t=0.5,\n",
       "                                random_state=42, shuffle=True, solver='adam',\n",
       "                                tol=0.0001, validation_fraction=0.1,\n",
       "                                verbose=False, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'final_model_pycaret_large_class.pkl')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(final_model, 'final_model_pycaret_large_class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a215037b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3B) **Opção B** — Sklearn + Imbalanced-learn (SMOTE **apenas no treino** via Pipeline)\n",
    "\n",
    "- Pipeline aplica `StandardScaler` → `SMOTE` (somente no `fit`) → `LogisticRegression`.\n",
    "- Validação com `RepeatedStratifiedKFold` no treino e, ao final, avaliação no teste externo.\n",
    "\n",
    "> Ajuste o class_weight, modelo ou métricas conforme necessidade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ea18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV f1_macro (mean±std): 0.7759 ± 0.0496\n",
      "\n",
      "Classification report (teste):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    large-class     0.3077    0.5000    0.3810         8\n",
      "non-large-class     0.9975    0.9945    0.9960      1626\n",
      "\n",
      "       accuracy                         0.9920      1634\n",
      "      macro avg     0.6526    0.7472    0.6885      1634\n",
      "   weighted avg     0.9942    0.9920    0.9930      1634\n",
      "\n",
      "Confusion matrix (teste):\n",
      "[[   4    4]\n",
      " [   9 1617]]\n",
      "ROC-AUC (teste): 0.7659\n",
      "PR-AUC  (teste): 0.9983\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3B) Sklearn + Imbalanced-learn\n",
    "# =========================\n",
    "# Para casos com recursos numéricos; se tiver categóricas, considere OneHotEncoder ou SMOTENC.\n",
    "numeric_pipeline = ImbPipeline(steps=[\n",
    "    ('scale', StandardScaler(with_mean=False) if hasattr(X_train, 'tocsc') else StandardScaler()),\n",
    "    ('smote', SMOTE(k_neighbors=5, random_state=42)),\n",
    "    ('clf', LogisticRegression(max_iter=5000, class_weight='balanced', n_jobs=None))\n",
    "])\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "scores = cross_val_score(numeric_pipeline, X_train, y_train, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "print(f'CV f1_macro (mean±std): {scores.mean():.4f} ± {scores.std():.4f}')\n",
    "\n",
    "# Fit no treino e avaliar no teste\n",
    "numeric_pipeline.fit(X_train, y_train)\n",
    "y_pred_test = numeric_pipeline.predict(X_test)\n",
    "\n",
    "print('\\nClassification report (teste):')\n",
    "print(classification_report(y_test, y_pred_test, digits=4))\n",
    "print('Confusion matrix (teste):')\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Se modelo tiver predict_proba, calcular AUCs\n",
    "try:\n",
    "    y_prob_test = numeric_pipeline.predict_proba(X_test)[:, 1]\n",
    "    # Mapear y_test para {0,1} se necessário\n",
    "    if y_test.dtype.name == 'category':\n",
    "        y_true_bin = (y_test.cat.codes.values).astype(int)\n",
    "    else:\n",
    "        # tentativa genérica (ajuste se necessário)\n",
    "        classes = sorted(list(pd.Series(y_test).unique()))\n",
    "        mapping = {cls:i for i, cls in enumerate(classes)}\n",
    "        y_true_bin = pd.Series(y_test).map(mapping).values\n",
    "    print(f'ROC-AUC (teste): {roc_auc_score(y_true_bin, y_prob_test):.4f}')\n",
    "    print(f'PR-AUC  (teste): {average_precision_score(y_true_bin, y_prob_test):.4f}')\n",
    "except Exception as e:\n",
    "    print('AUCs não calculadas:', e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
